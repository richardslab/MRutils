---
title: Vitamin D - COVID-19 MR (redo)
output: pdf_document
params:
  outcome_gwas: COVID-A2
  exposure_name: Vitamin D
  prefix: VD_A2
  pop: !r c("CEU", "TSI", "GBR", "IBS")
  LDLink_token: "151d285edb97"
  #LDLink_token: "<NEED INPUT>"
  near_half_threshold: 0.08
  exposure_pvalue_threshold: !r as.numeric("5e-5") #needs !r otherwise it's interpreted as a string....
  MAF_rare_threshold: 0.01
  prune_r2_threshold: 0.05
  outcome_file: ../raw_data/COVID19_HGI_A2_ALL_leave_23andme_20201020.b37.txt.gz
  results_dir: ../derived_data

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set("root.dir", "~/RichardsLab/VitaminD_COVID_MR_reproduce/scripts")
knitr::opts_chunk$set(cache = TRUE)

```

```{r libraries and setup}
require(tidyr)
require(plyr)
require(dplyr)
require(readxl)
require(glue)
require(magrittr)
require(ggplot2)

source("utils.R")

for (i in names(params)) { 
  if (i != "LDLink_token") 
    print(glue("{i} = {params[i]}")) 
  else 
    print(glue("{i} = [redacted]"))
}

incompatible=c("rs10832311","rs7412")

```


## Extract data from VitaminD GWAS
Since the input data is given to us as an excel spreadsheet, we have to extract the information from it
"manually". In order to avoid copy-paste errors, we extract the information using the readxl library. 

```{r extract excelsheet data}

data = read_excel("../raw_data/1-s2.0-S0002929720300173-mmc2.xlsx", 
                  sheet = "Table S2", 
                  skip = 4, 
                  .name_repair = "minimal") %>% subset(select = c(1:5, 13:17))

first_blank = min(which(is.na(data$RSID)))
# use the first blank line as an indication of the end of the data, since the dictionary comes after
if (length(first_blank) == 1) {
  data = data[1:min(first_blank - 1, nrow(data)),]
}
names(data)[8] = "beta"
names(data)[1] = "rsid"
data = data %>% mutate_at(.vars = c("EAF", "MAF", "beta", "SE", "P"), as.numeric)
data = data %>% mutate(POS = BP, CHR = gsub("^chr", "", CHR))

significant_snps <- filter_and_write_exposure_data(data, 
                                                   location_prefix = glue("{params$results_dir}/{params$prefix}_"), 
                                                   params$exposure_pvalue_threshold, 
                                                   params$MAF_rare_threshold)

```
### Outcome  

## extract relevant SNPs
```{r extract Snps}

map_outcome_data <- function(x) {
  
  mutate(x, 
         beta = all_inv_var_meta_beta, 
         P = all_inv_var_meta_p, 
         EA = ALT, 
         NEA = REF, 
         MAF = all_meta_AF, 
         EAF = all_meta_AF, 
         SE = all_inv_var_meta_sebeta) %>% 
      select(all_of(required_headers))
  
}

 
  outcome_data <- extract_snps_from_bgzip(outcome = params$outcome_file, snps = significant_snps) %>% map_outcome_data()
  
  print(glue("There are {nrow(outcome_data)} SNPs in the outcome data"))
```

## find names for un-named snps
```{r find_unnamed_snps, cache=TRUE}
## this can take time and hits the API multiple times....
print(glue("There are {nrow(outcome_data%>%subset(is.na(rsid)))} SNPs in the outcome data that are missing their rsid"))

withIds <- get_unknown_rsids_from_locus(outcome_data)
print(glue("{nrow(withIds)} SNPs rsids were found"))


write.table(withIds, glue("{params$results_dir}/{params$prefix}_rsIdsFromdbSnp.txt"), quote = F, sep = '\t', row.names = F)
```

```{r post-cache read variable}
withIds <- read.table(glue("{params$results_dir}/{params$prefix}_rsIdsFromdbSnp.txt"), sep = '\t', header = T)

```

## merge into other data
```{r merge found snps into data}
outcome_with_rsids <- merge_rsids_into_gwas(outcome_data, withIds)
  
print(glue("After merging the results, there are {nrow(outcome_with_rsids%>%subset(is.na(rsid)))} variants lacking rsid, and {nrow(outcome_with_rsids)} variants overall."))
```

```{r merge exposure and outcome}
merged_exp_and_out <- merge(significant_snps, suffixes = c(".exp", ".out"),
                          outcome_with_rsids, 
                          by = c("rsid", "CHR", "POS"), 
                          all.x = T,
                          )
subset(merged_exp_and_out, rsid %in% incompatible)

print(glue("After merging Exposure and Outcome, there are {nrow(merged_exp_and_out%>%subset(is.na(beta.out)))} variants lacking 'beta.out', and {nrow(merged_exp_and_out)} variants overall."))
```

```{r get proxies, cache=TRUE}

##takes time (hits the LDLink API)
proxies_raw <- get_proxies(subset(merged_exp_and_out, is.na(MAF.out))$rsid, params$LDLink_token, population = params$pop, results_dir = params$results_dir, skip_api = TRUE)

print(glue("Found {nrow(proxies_raw)} proxies for {length( unique(proxies_raw$query_rsid))} variants, out of {length(which(is.na(merged_exp_and_out$MAF.out)))} requested"))
```

```{r use proxies}
#subset to proxies that are in the outcome first, since we need to find out which proxies are present in the outcome
proxies_in_outcome <- extract_snps_from_bgzip(params$outcome_file, snps = proxies_raw) %>% map_outcome_data()

subset(proxies_in_outcome,rsid %in% incompatible)

proxies <- proxies_raw %>% subset(rsid %in% proxies_in_outcome$rsid)

print(glue("{nrow(proxies)} proxies (of {nrow(proxies_raw)}) were found in the outcome...."))
```

```{r merge proxies and exposure}
# merge proxies with exposure
exposure_and_proxies <- merge(proxies, significant_snps, by.x = c("query_rsid","CHR"), by.y = c("rsid","CHR"), suffixes = c(".proxy",".exp"))
print(glue("...and {nrow(exposure_and_proxies)} proxies were successfully merged with the exposure."))

# remove chimeric snps and then the smallest P
proxies_with_exposure <- exposure_and_proxies %>% 
  mutate(maf_near_half = abs(MAF.exp - 0.5) <= params$near_half_threshold, 
         distance_to_query = abs(POS.exp - POS.proxy)) %>%
  subset( !(Alleles %in% chimeric & maf_near_half)) %>%
  group_by(query_rsid) %>%
  slice_max(order_by = R2, n = 1, with_ties = TRUE) %>%
  slice_min(order_by = distance_to_query, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  mutate(maf_near_half = NULL, 
         distance_to_query = NULL) 

print(glue("After removing ambiguous snps and choosing the most linked SNP for every query, {nrow(proxies_with_exposure)} proxies remain."))

subset(proxies_with_exposure,rsid %in% incompatible,select=c("Alleles","Correlated_Alleles","rsid","EA","NEA"))

with(proxies_with_exposure, Alleles==glue("({EA}/{NEA})") |Alleles==glue("({NEA}/{EA})"))
subset(proxies_with_exposure,select=c(Alleles,Correlated_Alleles,rsid,EA,NEA))
```


```{r fix-proxy-alleles}

fixed_proxies_with_exposure <- adply(proxies_with_exposure, 1, function(x) {
  replace_alleles(list(x$EA, x$NEA), x$Correlated_Alleles) %>%
    {
  data.frame(
    EA = .[1],
    NEA = .[2]
    )}
  })

if (!all(with(fixed_proxies_with_exposure, Alleles == glue("({EA}/{NEA})") | Alleles == glue("({NEA}/{EA})")))) {
  warn("there was a problem fixing the alleles")
  subset(fixed_proxies_with_exposure, rsid %in% incompatible, select = c("Alleles", "Correlated_Alleles", "rsid", "EA", "NEA"))
}


```

```{r merge proxy rows with outcome and combine with rest}

merged_with_proxies <- merge(proxies_in_outcome,
                             fixed_proxies_with_exposure,
                             suffixes = c(".out",".exp"),
                             by.x = c("rsid", "CHR"),
                             by.y = c("rsid", "CHR")) %>%
  mutate(MAF.out = MAF, MAF = NULL) %>%
  select(c(-POS.proxy, -POS.exp, -R2, -Correlated_Alleles, -Alleles, -Locus, -MAF.proxy))

merged_and_combined <- rbind(merged_with_proxies, mutate(merged_exp_and_out, query_rsid = NA), stringsAsFactors = FALSE) %>% subset(!is.na(MAF.out))
print(glue("Total number of SNPs for use in 2-Sample MR (prior to pruning): {nrow(merged_and_combined)}."))



```

Now we need to make sure that we do not have SNPs in high LD next to each other

```{r prune_snps, cache = TRUE}
print(glue("pruning using populations: {params$pop}"))

ld_pairs_raw <- get_LD_pairs(merged_and_combined, population = params$pop, token = params$LDLink_token)

unique_rsids <- with(ld_pairs_raw, unique(c(as.character(RS_number), as.character(variable))))
ld_pairs <- ld_pairs_raw %>% mutate(
  variable = factor(variable, levels = unique_rsids),
  RS_number = factor(RS_number, levels = unique_rsids))

p = ggplot(ld_pairs) +  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + geom_bin2d(stat = 'identity', aes(x = RS_number, y = variable))
    
show(p + aes(fill = value) + labs(fill = expression(R^2), parse = TRUE))
show(p + aes(fill = value > params$prune_r2_threshold) + labs(fill = expression(R^2>threshold), parse = TRUE))


```

```{r }
list_result <- prune_snps(merged_and_combined, ld_pairs, params$prune_r2_threshold)


pruned_combined_snps <- list_result$rsids
removed_rsids <- list_result$removed_rsid

ggplot(ld_pairs) +  
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  geom_bin2d(stat = 'identity', aes(x = RS_number, y = variable)) +
  aes(fill = value > params$prune_r2_threshold, alpha = RS_number %in% removed_rsids | variable %in% removed_rsids) + 
  labs(fill = expression(R^2>threshold), alpha = "variant removed", parse = TRUE) + 
  scale_alpha_manual(values = c(0.3, 1), breaks = c(TRUE, FALSE))
 
print(glue("Removed {length(removed_rsids)} snps due to high LD (removed): "))
print(glue_collapse(glue("{removed_rsids} ")))
print(glue("Total number of SNPs for use in 2-Sample MR (pruned): {nrow(pruned_combined_snps)}."))

write.table(pruned_combined_snps, file = glue("{params$results_dir}/{params$prefix}_SNPsFor2SMR.txt"), sep = '\t', quote = F, row.names = F)
```

```{r get MR results}
results <- get_2smr_results(glue("{params$results_dir}/{params$prefix}_SNPsFor2SMR.txt"))
```
```{r show results}

for (p in results) {
  show(p)
}
save(results, file = glue("{params$results_dir}/{params$prefix}_2SMR_results.RData"))

```




